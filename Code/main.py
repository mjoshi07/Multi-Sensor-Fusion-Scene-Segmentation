# -*- coding: utf-8 -*-
"""ENPM673_final_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LOHdw1DHZa-Xcu1byEGplsl1EO47WWoZ
"""

# imports
import torch
import torch.nn as nn
from torch.utils.data import DataLoader

from FusionData import FusionDataset
from FusionNet import FusionNet, count_parameters
from training import train

# Params
epochs = 100
lr = 1e-5
epochs_till_chkpt = 1
batch_size = 100
model_dir = '../Data/vkitti'
lidar = True
optical_flow = True

# Loss function
loss_func = nn.CrossEntropyLoss()

# Model
model = FusionNet(out_channels=3, input_shape=(93, 310), lidar=lidar, optical_flow=optical_flow)
params = count_parameters(model)
print('===========================================================')
print(f'Starting training with lidar: {lidar}, optical flow: {optical_flow}')
print(f'Number of model parameters: {params}')
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f'Device: {device}')
if torch.cuda.is_available():
    print('CUDA enabled GPU found!')
    model = model.to(device)
else:
    print('CUDA enabled GPU not found! Using CPU.')
print('===========================================================')

# Dataset and dataloader
dataset = FusionDataset('../Data/vkitti')
total_length = len(dataset)
train_length = int(0.9 * total_length)
val_length = total_length - train_length
train_dataset, val_dataset = torch.utils.data.random_split(dataset,[train_length, val_length])
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)

# Train!
train(model, train_dataloader, epochs, lr, epochs_till_chkpt, model_dir,
      loss_func, validation_dataloader=val_dataloader)
